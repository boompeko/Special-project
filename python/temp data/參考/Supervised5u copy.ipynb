{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1540 entries, 0 to 1539\n",
      "Data columns (total 7 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   Date                  1540 non-null   int64  \n",
      " 1    Average Temperature  1540 non-null   float64\n",
      " 2   Anomaly               1540 non-null   float64\n",
      " 3    Maximum Temperature  1540 non-null   float64\n",
      " 4   Anomaly.1             1540 non-null   float64\n",
      " 5    Minimum Temperature  1540 non-null   float64\n",
      " 6   Anomaly.2             1540 non-null   float64\n",
      "dtypes: float64(6), int64(1)\n",
      "memory usage: 84.3 KB\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Importing the data from a csv file to a DataFrame\n",
    "df = pd.read_csv(\"Kansas.CSV\")\n",
    "# Showing the first five values of the DataFrame\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.89501e+05  2.35000e+01 -5.10000e+00 ... -5.70000e+00  1.27000e+01\n",
      "  -4.50000e+00]\n",
      " [ 1.89502e+05  2.39000e+01 -9.50000e+00 ... -1.03000e+01  1.23000e+01\n",
      "  -8.70000e+00]\n",
      " [ 1.89503e+05  4.20000e+01 -2.00000e-01 ...  1.10000e+00  2.79000e+01\n",
      "  -1.60000e+00]\n",
      " ...\n",
      " [ 2.02302e+05  3.53000e+01  1.90000e+00 ...  3.70000e+00  2.10000e+01\n",
      "   0.00000e+00]\n",
      " [ 2.02303e+05  4.21000e+01 -1.00000e-01 ... -5.00000e-01  2.97000e+01\n",
      "   2.00000e-01]\n",
      " [ 2.02304e+05  5.47000e+01  1.10000e+00 ...  3.70000e+00  3.90000e+01\n",
      "  -1.50000e+00]]\n",
      "[23.5 23.9 42.  ... 35.3 42.1 54.7]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "filename = 'Kansas.CSV'\n",
    "\n",
    "# 读取CSV文件\n",
    "data = pd.read_csv(filename)\n",
    "\n",
    "\n",
    "transposed_data = data.transpose()\n",
    "# 将数据转换为数组\n",
    "data_array = transposed_data.values\n",
    "\n",
    "target = data_array[1]\n",
    "\n",
    "data_array = data.values\n",
    "\n",
    "\n",
    "target = target.flatten()\n",
    "\n",
    "\n",
    "print(data_array)\n",
    "print(target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "y should be a 1d array, got an array of shape (1540, 7) instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[46], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m y \u001b[39m=\u001b[39m target\n\u001b[0;32m      8\u001b[0m label_encoder \u001b[39m=\u001b[39m LabelEncoder()\n\u001b[1;32m----> 9\u001b[0m X \u001b[39m=\u001b[39m label_encoder\u001b[39m.\u001b[39;49mfit_transform(X)\n\u001b[0;32m     10\u001b[0m y \u001b[39m=\u001b[39m label_encoder\u001b[39m.\u001b[39mfit_transform(y)\n\u001b[0;32m     12\u001b[0m ratio \u001b[39m=\u001b[39m \u001b[39m100\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\JOU\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[0;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 140\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    141\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[0;32m    142\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    143\u001b[0m         \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[0;32m    145\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[0;32m    146\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\JOU\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:116\u001b[0m, in \u001b[0;36mLabelEncoder.fit_transform\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit_transform\u001b[39m(\u001b[39mself\u001b[39m, y):\n\u001b[0;32m    104\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Fit label encoder and return encoded labels.\u001b[39;00m\n\u001b[0;32m    105\u001b[0m \n\u001b[0;32m    106\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[39m        Encoded labels.\u001b[39;00m\n\u001b[0;32m    115\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 116\u001b[0m     y \u001b[39m=\u001b[39m column_or_1d(y, warn\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m    117\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_, y \u001b[39m=\u001b[39m _unique(y, return_inverse\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m    118\u001b[0m     \u001b[39mreturn\u001b[39;00m y\n",
      "File \u001b[1;32mc:\\Users\\JOU\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\validation.py:1202\u001b[0m, in \u001b[0;36mcolumn_or_1d\u001b[1;34m(y, dtype, warn)\u001b[0m\n\u001b[0;32m   1193\u001b[0m         warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m   1194\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mA column-vector y was passed when a 1d array was\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1195\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m expected. Please change the shape of y to \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1198\u001b[0m             stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m,\n\u001b[0;32m   1199\u001b[0m         )\n\u001b[0;32m   1200\u001b[0m     \u001b[39mreturn\u001b[39;00m _asarray_with_order(xp\u001b[39m.\u001b[39mreshape(y, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m), order\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mC\u001b[39m\u001b[39m\"\u001b[39m, xp\u001b[39m=\u001b[39mxp)\n\u001b[1;32m-> 1202\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1203\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39my should be a 1d array, got an array of shape \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m instead.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(shape)\n\u001b[0;32m   1204\u001b[0m )\n",
      "\u001b[1;31mValueError\u001b[0m: y should be a 1d array, got an array of shape (1540, 7) instead."
     ]
    }
   ],
   "source": [
    "# Decision Tree (Split data randomly from 90~10% + different depth + different min sample leaf)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import tree\n",
    "\n",
    "X = data_array\n",
    "y = target\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "X = label_encoder.fit_transform(X)\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "ratio = 100\n",
    "ratiovalues = [i for i in range(10, ratio, 10)]\n",
    "depth = 21\n",
    "depthvalues = [i for i in range(1, depth)]\n",
    "leaf = 10\n",
    "leafvalues = [i for i in range(1, leaf)]\n",
    "relative_best_train_score = 0\n",
    "relative_best_test_score = 0\n",
    "relative_best_ratio = 0\n",
    "relative_best_depth = 0\n",
    "relative_best_leaf = 0\n",
    "\n",
    "for k in ratiovalues:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = k/100, random_state=71)\n",
    "    for i in depthvalues:\n",
    "        for j in leafvalues:\n",
    "            clf = tree.DecisionTreeClassifier(random_state = 71, max_depth = i, min_samples_leaf = j)\n",
    "            clf.fit(X_train, y_train)\n",
    "            y_pred_train = clf.predict(X_train) #train\n",
    "            train_acc = accuracy_score(y_pred_train, y_train)\n",
    "            y_pred_test = clf.predict(X_test) #train\n",
    "            test_acc = accuracy_score(y_pred_test, y_test)\n",
    "\n",
    "            if ((train_acc > relative_best_train_score) and (test_acc > relative_best_test_score)):\n",
    "                relative_best_train_score = train_acc\n",
    "                relative_best_test_score = test_acc\n",
    "                relative_best_ratio = k\n",
    "                relative_best_depth = i\n",
    "                relative_best_leaf = j\n",
    "\n",
    "print(\"best ratio of testing data:\", relative_best_ratio, \"best depth:\", relative_best_depth, \"best min_sample_leaf:\", relative_best_leaf, \\\n",
    "      \"\\nTraining score:\", relative_best_train_score, \"Testing score:\", relative_best_test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomizedSearchCV(estimator=DecisionTreeClassifier(),\n",
      "                   param_distributions=[{'max_depth': [1, 2, 3, 4, 5, 6, 7, 8,\n",
      "                                                       9, 10, 11, 12, 13, 14,\n",
      "                                                       15, 16, 17, 18, 19,\n",
      "                                                       20]},\n",
      "                                        {'min_samples_leaf': [1, 2, 3, 4, 5, 6,\n",
      "                                                              7, 8, 9]},\n",
      "                                        {'random_state': [71]}],\n",
      "                   random_state=10)\n",
      "============================================================\n",
      "best parameters' values: {'max_depth': 2} best scoure: 0.9252747252747252\n",
      "============================================================\n",
      "all combinations' results:\n",
      " {'mean_fit_time': array([0.00478754, 0.00438628, 0.00399685, 0.00277882, 0.00357637,\n",
      "       0.00399199, 0.00419059, 0.00339203, 0.00437603, 0.00260448]), 'std_fit_time': array([7.48002697e-04, 7.84330490e-04, 6.41882665e-04, 7.34185143e-04,\n",
      "       4.77833675e-04, 2.10914082e-05, 7.37964201e-04, 4.76135749e-04,\n",
      "       7.91484152e-04, 4.81466117e-04]), 'mean_score_time': array([0.00039978, 0.00059876, 0.00039868, 0.00060663, 0.0002058 ,\n",
      "       0.00079188, 0.00019979, 0.000594  , 0.00039949, 0.00059919]), 'std_score_time': array([0.00048963, 0.00048889, 0.00048829, 0.00049548, 0.00041161,\n",
      "       0.00039611, 0.00039959, 0.00048518, 0.00048928, 0.00048924]), 'param_min_samples_leaf': masked_array(data=[1, --, --, --, --, 2, --, 8, --, --],\n",
      "             mask=[False,  True,  True,  True,  True, False,  True, False,\n",
      "                    True,  True],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_max_depth': masked_array(data=[--, 8, 6, 3, 4, --, 14, --, 13, 2],\n",
      "             mask=[ True, False, False, False, False,  True, False,  True,\n",
      "                   False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'min_samples_leaf': 1}, {'max_depth': 8}, {'max_depth': 6}, {'max_depth': 3}, {'max_depth': 4}, {'min_samples_leaf': 2}, {'max_depth': 14}, {'min_samples_leaf': 8}, {'max_depth': 13}, {'max_depth': 2}], 'split0_test_score': array([0.91208791, 0.94505495, 0.91208791, 0.92307692, 0.91208791,\n",
      "       0.91208791, 0.86813187, 0.92307692, 0.91208791, 0.91208791]), 'split1_test_score': array([0.9010989 , 0.9010989 , 0.94505495, 0.93406593, 0.92307692,\n",
      "       0.92307692, 0.93406593, 0.92307692, 0.91208791, 0.96703297]), 'split2_test_score': array([0.91208791, 0.9010989 , 0.9010989 , 0.89010989, 0.89010989,\n",
      "       0.85714286, 0.86813187, 0.87912088, 0.86813187, 0.92307692]), 'split3_test_score': array([0.87912088, 0.89010989, 0.87912088, 0.89010989, 0.86813187,\n",
      "       0.9010989 , 0.86813187, 0.86813187, 0.87912088, 0.9010989 ]), 'split4_test_score': array([0.93406593, 0.93406593, 0.93406593, 0.91208791, 0.92307692,\n",
      "       0.91208791, 0.93406593, 0.92307692, 0.93406593, 0.92307692]), 'mean_test_score': array([0.90769231, 0.91428571, 0.91428571, 0.90989011, 0.9032967 ,\n",
      "       0.9010989 , 0.89450549, 0.9032967 , 0.9010989 , 0.92527473]), 'std_test_score': array([0.01785503, 0.02130848, 0.02346611, 0.01758242, 0.02130848,\n",
      "       0.02305074, 0.03230096, 0.02447369, 0.02407572, 0.02241327]), 'rank_test_score': array([ 5,  2,  2,  4,  6,  8, 10,  6,  8,  1])}\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree RandomizedSearchCV\n",
    "# (Split training and testing data randomly (80% vs. 20%) + \n",
    "# different depth + different min sample leaf)\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "from sklearn import tree\n",
    "X = cancer.data\n",
    "y = cancer.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=71) #train_size = 0.8\n",
    "\n",
    "depth = 21\n",
    "depthvalues = [i for i in range(1, depth)]\n",
    "leaf = 10\n",
    "leafvalues = [i for i in range(1, leaf)]\n",
    "randomvalue = [71]\n",
    "\n",
    "tree_param = [{\"max_depth\": depthvalues},\n",
    "              {\"min_samples_leaf\": leafvalues},\n",
    "              {\"random_state\": randomvalue}]\n",
    "\n",
    "clf = RandomizedSearchCV(tree.DecisionTreeClassifier(), tree_param, random_state = 10)\n",
    "\n",
    "random_result = clf.fit(X_train, y_train)\n",
    "print(random_result)\n",
    "\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"best parameters' values:\", random_result.best_params_, \"best scoure:\", random_result.best_score_)\n",
    "\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"all combinations' results:\\n\", clf.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV(estimator=DecisionTreeClassifier(),\n",
      "             param_grid=[{'max_depth': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,\n",
      "                                        13, 14, 15, 16, 17, 18, 19, 20]},\n",
      "                         {'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9]},\n",
      "                         {'random_state': [71]}])\n",
      "============================================================\n",
      "best parameters' values: {'max_depth': 2} best scoure: 0.923076923076923\n",
      "============================================================\n",
      "all combinations' results:\n",
      " {'mean_fit_time': array([0.00219831, 0.00220327, 0.00319118, 0.00398278, 0.00400023,\n",
      "       0.0044013 , 0.00439591, 0.0041822 , 0.00398922, 0.00398526,\n",
      "       0.00418205, 0.00399175, 0.00458741, 0.00419507, 0.00398226,\n",
      "       0.00399585, 0.00438724, 0.00398893, 0.00420237, 0.00457897,\n",
      "       0.00479021, 0.00397859, 0.00419326, 0.00418682, 0.00387206,\n",
      "       0.00380168, 0.0033843 , 0.00359335, 0.00319748, 0.00437465]), 'std_fit_time': array([3.90720658e-04, 3.95117104e-04, 4.12928105e-04, 3.16251259e-05,\n",
      "       6.19265838e-04, 4.79804808e-04, 5.02927260e-04, 3.86852159e-04,\n",
      "       8.92976614e-04, 8.92219251e-04, 4.02559739e-04, 6.30489349e-04,\n",
      "       7.97331416e-04, 7.54497864e-04, 2.27498803e-05, 6.46238234e-04,\n",
      "       5.04352369e-04, 6.30675638e-04, 4.08153806e-04, 7.93938574e-04,\n",
      "       7.43090237e-04, 6.46477710e-04, 7.42702421e-04, 3.95558321e-04,\n",
      "       4.76391264e-04, 3.90256960e-04, 4.80917553e-04, 8.09912294e-04,\n",
      "       3.97305213e-04, 4.87695833e-04]), 'mean_score_time': array([0.00039635, 0.00039415, 0.        , 0.        , 0.0004004 ,\n",
      "       0.00057907, 0.        , 0.00019946, 0.00039911, 0.0001996 ,\n",
      "       0.00040555, 0.00039625, 0.00039897, 0.00019951, 0.00039887,\n",
      "       0.00039859, 0.        , 0.00059867, 0.00059547, 0.        ,\n",
      "       0.00060182, 0.00040998, 0.0003993 , 0.00019984, 0.0003931 ,\n",
      "       0.00039902, 0.00059862, 0.00039897, 0.00059876, 0.00039887]), 'std_score_time': array([0.00048544, 0.00048286, 0.        , 0.        , 0.00049039,\n",
      "       0.00047327, 0.        , 0.00039892, 0.00048881, 0.00039921,\n",
      "       0.00049679, 0.00048533, 0.00048864, 0.00039902, 0.00048852,\n",
      "       0.00048817, 0.        , 0.00048881, 0.00048623, 0.        ,\n",
      "       0.00049141, 0.00050244, 0.00048904, 0.00039968, 0.00048155,\n",
      "       0.00048869, 0.00048877, 0.00048864, 0.00048889, 0.00048852]), 'param_max_depth': masked_array(data=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16,\n",
      "                   17, 18, 19, 20, --, --, --, --, --, --, --, --, --, --],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False,  True,  True,  True,  True,\n",
      "                    True,  True,  True,  True,  True,  True],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_min_samples_leaf': masked_array(data=[--, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
      "                   --, --, --, --, --, --, 1, 2, 3, 4, 5, 6, 7, 8, 9, --],\n",
      "             mask=[ True,  True,  True,  True,  True,  True,  True,  True,\n",
      "                    True,  True,  True,  True,  True,  True,  True,  True,\n",
      "                    True,  True,  True,  True, False, False, False, False,\n",
      "                   False, False, False, False, False,  True],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_random_state': masked_array(data=[--, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
      "                   --, --, --, --, --, --, --, --, --, --, --, --, --, --,\n",
      "                   --, 71],\n",
      "             mask=[ True,  True,  True,  True,  True,  True,  True,  True,\n",
      "                    True,  True,  True,  True,  True,  True,  True,  True,\n",
      "                    True,  True,  True,  True,  True,  True,  True,  True,\n",
      "                    True,  True,  True,  True,  True, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'max_depth': 1}, {'max_depth': 2}, {'max_depth': 3}, {'max_depth': 4}, {'max_depth': 5}, {'max_depth': 6}, {'max_depth': 7}, {'max_depth': 8}, {'max_depth': 9}, {'max_depth': 10}, {'max_depth': 11}, {'max_depth': 12}, {'max_depth': 13}, {'max_depth': 14}, {'max_depth': 15}, {'max_depth': 16}, {'max_depth': 17}, {'max_depth': 18}, {'max_depth': 19}, {'max_depth': 20}, {'min_samples_leaf': 1}, {'min_samples_leaf': 2}, {'min_samples_leaf': 3}, {'min_samples_leaf': 4}, {'min_samples_leaf': 5}, {'min_samples_leaf': 6}, {'min_samples_leaf': 7}, {'min_samples_leaf': 8}, {'min_samples_leaf': 9}, {'random_state': 71}], 'split0_test_score': array([0.87912088, 0.91208791, 0.93406593, 0.91208791, 0.9010989 ,\n",
      "       0.91208791, 0.93406593, 0.9010989 , 0.89010989, 0.9010989 ,\n",
      "       0.87912088, 0.91208791, 0.91208791, 0.87912088, 0.93406593,\n",
      "       0.87912088, 0.91208791, 0.9010989 , 0.89010989, 0.91208791,\n",
      "       0.9010989 , 0.91208791, 0.9010989 , 0.92307692, 0.93406593,\n",
      "       0.93406593, 0.92307692, 0.92307692, 0.92307692, 0.93406593]), 'split1_test_score': array([0.91208791, 0.96703297, 0.94505495, 0.89010989, 0.92307692,\n",
      "       0.91208791, 0.93406593, 0.92307692, 0.89010989, 0.94505495,\n",
      "       0.91208791, 0.89010989, 0.91208791, 0.91208791, 0.91208791,\n",
      "       0.92307692, 0.9010989 , 0.92307692, 0.92307692, 0.93406593,\n",
      "       0.91208791, 0.9010989 , 0.91208791, 0.91208791, 0.93406593,\n",
      "       0.93406593, 0.92307692, 0.92307692, 0.9010989 , 0.93406593]), 'split2_test_score': array([0.84615385, 0.91208791, 0.9010989 , 0.91208791, 0.87912088,\n",
      "       0.93406593, 0.86813187, 0.9010989 , 0.87912088, 0.9010989 ,\n",
      "       0.89010989, 0.87912088, 0.9010989 , 0.89010989, 0.87912088,\n",
      "       0.87912088, 0.91208791, 0.91208791, 0.91208791, 0.87912088,\n",
      "       0.9010989 , 0.86813187, 0.89010989, 0.92307692, 0.87912088,\n",
      "       0.87912088, 0.89010989, 0.9010989 , 0.87912088, 0.89010989]), 'split3_test_score': array([0.89010989, 0.9010989 , 0.89010989, 0.89010989, 0.87912088,\n",
      "       0.87912088, 0.86813187, 0.87912088, 0.86813187, 0.89010989,\n",
      "       0.9010989 , 0.87912088, 0.86813187, 0.89010989, 0.87912088,\n",
      "       0.87912088, 0.87912088, 0.86813187, 0.87912088, 0.87912088,\n",
      "       0.87912088, 0.87912088, 0.9010989 , 0.91208791, 0.91208791,\n",
      "       0.9010989 , 0.87912088, 0.86813187, 0.9010989 , 0.87912088]), 'split4_test_score': array([0.87912088, 0.92307692, 0.92307692, 0.92307692, 0.92307692,\n",
      "       0.91208791, 0.93406593, 0.91208791, 0.92307692, 0.92307692,\n",
      "       0.92307692, 0.92307692, 0.92307692, 0.92307692, 0.94505495,\n",
      "       0.93406593, 0.93406593, 0.93406593, 0.93406593, 0.93406593,\n",
      "       0.93406593, 0.91208791, 0.91208791, 0.91208791, 0.92307692,\n",
      "       0.92307692, 0.93406593, 0.92307692, 0.93406593, 0.93406593]), 'mean_test_score': array([0.88131868, 0.92307692, 0.91868132, 0.90549451, 0.9010989 ,\n",
      "       0.90989011, 0.90769231, 0.9032967 , 0.89010989, 0.91208791,\n",
      "       0.9010989 , 0.8967033 , 0.9032967 , 0.8989011 , 0.90989011,\n",
      "       0.8989011 , 0.90769231, 0.90769231, 0.90769231, 0.90769231,\n",
      "       0.90549451, 0.89450549, 0.9032967 , 0.91648352, 0.91648352,\n",
      "       0.91428571, 0.90989011, 0.90769231, 0.90769231, 0.91428571]), 'std_test_score': array([0.02130848, 0.02305074, 0.02038158, 0.01318681, 0.01965774,\n",
      "       0.01758242, 0.03230096, 0.01457857, 0.01838813, 0.01965774,\n",
      "       0.01554081, 0.01785503, 0.01890621, 0.01615048, 0.02727401,\n",
      "       0.02447369, 0.01785503, 0.02262776, 0.02038158, 0.02467027,\n",
      "       0.01785503, 0.01785503, 0.00822342, 0.00538349, 0.02038158,\n",
      "       0.02130848, 0.02130848, 0.02153398, 0.01916   , 0.02447369]), 'rank_test_score': array([30,  1,  2, 18, 23,  8, 11, 20, 29,  7, 23, 27, 20, 25,  8, 25, 11,\n",
      "       11, 11, 11, 18, 28, 20,  3,  3,  5,  8, 11, 11,  5])}\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree GridSearchCV\n",
    "# (Split training and testing data randomly (80% vs. 20%) + \n",
    "# different depth + different min sample leaf)\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn import tree\n",
    "X = cancer.data\n",
    "y = cancer.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=71) #train_size = 0.8\n",
    "\n",
    "depth = 21\n",
    "depthvalues = [i for i in range(1, depth)]\n",
    "leaf = 10\n",
    "leafvalues = [i for i in range(1, leaf)]\n",
    "randomvalue = [71]\n",
    "\n",
    "tree_param = [{\"max_depth\": depthvalues},\n",
    "              {\"min_samples_leaf\": leafvalues},\n",
    "              {\"random_state\": randomvalue}]\n",
    "\n",
    "clf = GridSearchCV(tree.DecisionTreeClassifier(), tree_param)\n",
    "\n",
    "grid_result = clf.fit(X_train, y_train)\n",
    "print(grid_result)\n",
    "\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"best parameters' values:\", grid_result.best_params_, \"best scoure:\", grid_result.best_score_)\n",
    "\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"all combinations' results:\\n\", clf.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 0.9277174947648963 {'max_depth': 4}\n",
      "20 0.9208791208791208 {'max_depth': 2}\n",
      "30 0.934620253164557 {'max_depth': 2}\n",
      "40 0.935464620630861 {'max_depth': 3}\n",
      "50 0.9260025062656642 {'min_samples_leaf': 5}\n",
      "60 0.9254106280193236 {'max_depth': 16}\n",
      "70 0.9235294117647058 {'max_depth': 1}\n",
      "80 0.9383399209486166 {'max_depth': 1}\n",
      "90 0.9818181818181818 {'min_samples_leaf': 3}\n",
      "\n",
      "best ratio: 90 best parameters' values: {'min_samples_leaf': 3} best scoure: 0.9818181818181818\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree GridSearchCV\n",
    "# (Split training and testing data randomly (from 90% ~ 10%) + \n",
    "# different depth + different min sample leaf)\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn import tree\n",
    "X = cancer.data\n",
    "y = cancer.target\n",
    "\n",
    "ratio = 100\n",
    "ratiovalues = [i for i in range(10, ratio, 10)]\n",
    "relative_best_score = 0\n",
    "relative_best_ratio = 0\n",
    "relative_best_param = \"\"\n",
    "\n",
    "\n",
    "for k in ratiovalues:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = k/100, random_state=71)\n",
    "\n",
    "    depth = 21\n",
    "    depthvalues = [i for i in range(1, depth)]\n",
    "    leaf = 10\n",
    "    leafvalues = [i for i in range(1, leaf)]\n",
    "    randomvalue = [71]\n",
    "\n",
    "    tree_param = [{\"max_depth\": depthvalues},\n",
    "                  {\"min_samples_leaf\": leafvalues},\n",
    "                  {\"random_state\": randomvalue}]\n",
    "\n",
    "    clf = GridSearchCV(tree.DecisionTreeClassifier(), tree_param)\n",
    "\n",
    "    grid_result = clf.fit(X_train, y_train)\n",
    "    \n",
    "    print(k, grid_result.best_score_, grid_result.best_params_)\n",
    "    \n",
    "    if (grid_result.best_score_ > relative_best_score):\n",
    "        relative_best_score = grid_result.best_score_\n",
    "        relative_best_ratio = k\n",
    "        relative_best_param = grid_result.best_params_\n",
    "\n",
    "print(\"\\nbest ratio:\", k, \"best parameters' values:\", relative_best_param, \"best scoure:\", relative_best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 0.9335427374833427 {'p': 1}\n",
      "20 0.9296703296703296 {'p': 1}\n",
      "30 0.9271835443037976 {'p': 1}\n",
      "40 0.9177749360613812 {'n_neighbors': 7}\n",
      "50 0.9156641604010025 {'n_neighbors': 9}\n",
      "60 0.9121739130434781 {'n_neighbors': 5}\n",
      "70 0.9411764705882353 {'n_neighbors': 3}\n",
      "80 0.9474308300395258 {'n_neighbors': 4}\n",
      "90 0.9818181818181818 {'n_neighbors': 1}\n",
      "\n",
      "best ratio: 90 best parameters' values: {'n_neighbors': 1} best scoure: 0.9818181818181818\n"
     ]
    }
   ],
   "source": [
    "# KNN + GridSearchCV\n",
    "# (Split training and testing data randomly (from 90% ~ 10%) + \n",
    "# different depth + different min sample leaf)\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn import neighbors\n",
    "X = cancer.data\n",
    "y = cancer.target\n",
    "\n",
    "ratio = 100\n",
    "ratiovalues = [i for i in range(10, ratio, 10)]\n",
    "relative_best_score = 0\n",
    "relative_best_ratio = 0\n",
    "relative_best_param = \"\"\n",
    "\n",
    "\n",
    "for k in ratiovalues:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = k/100, random_state=71)\n",
    "\n",
    "    neighbor = 10\n",
    "    neighborvalues = [i for i in range(1, neighbor)]\n",
    "    p = 3\n",
    "    pvalues = [i for i in range(1, p)]\n",
    "\n",
    "    knn_param = [{\"n_neighbors\": neighborvalues},\n",
    "                 {\"p\": pvalues}]\n",
    "\n",
    "    clf1 = GridSearchCV(neighbors.KNeighborsClassifier(), knn_param)\n",
    "    clf2 = GridSearchCV(tree(), tree_param)\n",
    "\n",
    "    \n",
    "    grid_result = clf.fit(X_train, y_train)\n",
    "    \n",
    "    print(k, grid_result.best_score_, grid_result.best_params_)\n",
    "    \n",
    "    if (grid_result.best_score_ > relative_best_score):\n",
    "        relative_best_score = grid_result.best_score_\n",
    "        relative_best_ratio = k\n",
    "        relative_best_param = grid_result.best_params_\n",
    "\n",
    "print(\"\\nbest ratio:\", k, \"best parameters' values:\", relative_best_param, \"best scoure:\", relative_best_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
